{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyf/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/wyf/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/wyf/.local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "/home/wyf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:33: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/home/wyf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:35: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.97700623073791"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import sys\n",
    "# import random\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "# from lightfm.data import Dataset\n",
    "import csv\n",
    "\n",
    "'''这个代码里推荐卖的最多的商品 - popular'''\n",
    "retail_data = pd.read_csv('/home/wyf/Desktop/mixed/train.csv')\n",
    "# retail_data = pd.read_csv('train.csv')\n",
    "# retail_data.drop(retail_data.columns[0],axis=1,inplace=True)\n",
    "\n",
    "retail_data['user_id'] = retail_data.user_id.astype(int)\n",
    "data = retail_data[['user_id', 'item_id', 'Occurrence']] # Get rid of unnecessary info\n",
    "\n",
    "item_lookup = retail_data[['item_id', 'cat_id']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['item_id'] = retail_data.item_id.astype(int) # Encode as strings for future lookup ease\n",
    "\n",
    "grouped_cleaned = data.groupby(['user_id', 'item_id']).sum().reset_index() # Group together\n",
    "grouped_cleaned.Occurrence.loc[grouped_cleaned.Occurrence == 0] = 1\n",
    "grouped_purchased = grouped_cleaned.query('Occurrence > 0')\n",
    "\n",
    "customers = list(np.sort(grouped_purchased.user_id.unique())) # Get our unique customers\n",
    "products = list(grouped_purchased.item_id.unique()) # Get our unique products that were purchased\n",
    "quantity = list(grouped_purchased.Occurrence)\n",
    "\n",
    "rows = grouped_purchased.user_id.astype('category', categories = customers).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = grouped_purchased.item_id.astype('category', categories = products).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))\n",
    "\n",
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity  # sparsity is 99.92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n",
      "5376\n",
      "82\n",
      "3535\n",
      "4360\n",
      "4073\n",
      "1573\n",
      "549\n",
      "2276\n",
      "3969\n",
      "6585\n",
      "1446\n",
      "7069\n",
      "1422\n",
      "1214\n",
      "8235\n",
      "3738\n",
      "6143\n",
      "187\n",
      "7577\n",
      "4874\n",
      "1866\n",
      "1662\n",
      "5795\n",
      "4290\n",
      "1552\n",
      "6326\n",
      "4705\n",
      "385\n",
      "3929\n"
     ]
    }
   ],
   "source": [
    "a = retail_data.brand_id.unique()\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2935"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pop_goods(data, num):\n",
    "    \n",
    "    '''找出买的最多的前num个商品'''\n",
    "    brand_list = data.brand_id.unique()\n",
    "    goods = []\n",
    "    for i in brand_list:\n",
    "        brand_data = data[data['brand_id']==i]\n",
    "        brand_data['total_occ'] = brand_data.groupby(['item_id']).cumcount(ascending=False)+1 # here every item appears only once to everybody\n",
    "        brand_data = brand_data.drop_duplicates(subset=['item_id'], keep='first')\n",
    "        brand_goods = list(brand_data.sort_values('total_occ', ascending=False).head(num).item_id)\n",
    "        goods = goods + brand_goods\n",
    "    \n",
    "    return goods\n",
    "\n",
    "popular = pop_goods(retail_data.copy(),100)\n",
    "len(popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166190"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_arr = np.array(customers) # Array of customer IDs from the ratings matrix\n",
    "products_arr = np.array(products) # Array of product IDs from the ratings matrix\n",
    "len(customers_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[144751, 294076, 1573],\n",
       " [35363, 403762, 7577],\n",
       " [35363, 159310, 7577],\n",
       " [392690, 981776, 4073],\n",
       " [392690, 1086021, 4073]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('/home/wyf/Desktop/mixed/test.txt', 'rb') as fp:\n",
    "# with open ('test.txt', 'rb') as fp:\n",
    "    test_set = pickle.load(fp) # 在explicit with cmf的变量名叫做product_users_altered\n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 40\n",
    "# user_vecs, item_vecs = implicit.alternating_least_squares((purchases_sparse*alpha).astype('double'), \n",
    "#                                                           factors=40, \n",
    "#                                                           regularization = 0.1, \n",
    "#                                                          iterations = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_items(customer_id, mf_train, user_vecs, item_vecs, customer_list, item_list, item_lookup, num_items = 10):\n",
    "    '''\n",
    "    This function will return the top recommended items to our users \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to get recommendations for\n",
    "    \n",
    "    mf_train - The training matrix you used for matrix factorization fitting\n",
    "    \n",
    "    user_vecs - the user vectors from your fitted matrix factorization\n",
    "    \n",
    "    item_vecs - the item vectors from your fitted matrix factorization\n",
    "    \n",
    "    customer_list - an array of the customer's ID numbers that make up the rows of your ratings matrix \n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_list - an array of the products that make up the columns of your ratings matrix\n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    num_items - The number of items you want to recommend in order of best recommendations. Default is 10. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - The top n recommendations chosen based on the user/item vectors for items never interacted with/purchased\n",
    "    '''\n",
    "    \n",
    "    cust_ind = np.where(customer_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    pref_vec = mf_train[cust_ind,:].toarray() # Get the ratings from the training set ratings matrix\n",
    "    pref_vec = pref_vec.reshape(-1) + 1 # Add 1 to everything, so that items not purchased yet become equal to 1\n",
    "    pref_vec[pref_vec > 1] = 0 # Make everything already purchased zero\n",
    "    rec_vector = user_vecs[cust_ind,:].dot(item_vecs.T) # Get dot product of user vector and all item vectors\n",
    "#     print(rec_vector)\n",
    "    # Scale this recommendation vector between 0 and 1\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "#     print(rec_vector_scaled)\n",
    "    recommend_vector = pref_vec*rec_vector_scaled\n",
    "    # Items already purchased have their recommendation multiplied by zero\n",
    "    product_idx = np.argsort(recommend_vector)[::-1][:num_items] # Sort the indices of the items into order \n",
    "    # of best recommendations\n",
    "    rec_list = [] # start empty list to store items\n",
    "    for index in product_idx:\n",
    "        code = item_list[index]\n",
    "#         rec_list.append([code, item_lookup.Description.loc[item_lookup.StockCode == code].iloc[0]]) \n",
    "        rec_list.append([code, item_lookup.cat_id.loc[item_lookup.item_id == code].iloc[0]]) \n",
    "        # Append our descriptions to the list\n",
    "    codes = [item[0] for item in rec_list]\n",
    "    descriptions = [item[1] for item in rec_list]\n",
    "    final_frame = pd.DataFrame({'item_id': codes, 'cat_id': descriptions}) # Create a dataframe \n",
    "    return final_frame[['item_id', 'cat_id']] # Switch order of columns around\n",
    "\n",
    "# total_rec = rec_items(, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,num_items = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(item, _list):\n",
    "    if item in _list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3032034278718629\n"
     ]
    }
   ],
   "source": [
    "def acc_topN_with_cat(altered_pair, num, pop):\n",
    "    count = 0\n",
    "#     print(len(altered_pair))\n",
    "    for i in range(len(altered_pair)):\n",
    "        \n",
    "        \n",
    "        rec_item = pd.DataFrame(pop)\n",
    "        rec_item.columns = ['item_id']\n",
    "        _item_cat = pd.merge(rec_item, item_lookup)\n",
    "\n",
    "        cat_topN = list(_item_cat.groupby('cat_id').head(num).item_id)\n",
    "\n",
    "        count = count + accuracy(altered_pair[i][1], cat_topN)\n",
    "    return count/len(altered_pair)\n",
    "\n",
    "topN_acc = acc_topN_with_cat(test_set, 5, popular)\n",
    "print(topN_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
