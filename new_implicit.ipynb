{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyf/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/wyf/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/wyf/.local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "/home/wyf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:38: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "/home/wyf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.80960592945222"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import sys\n",
    "# import random\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "# from lightfm.data import Dataset\n",
    "import csv\n",
    "from cmfrec import CMF\n",
    "\n",
    "# original_data = pd.read_csv('/home/wyf/Desktop/tmall/data.csv') # 在cold start里用\n",
    "# original_data.drop(original_data.columns[0],axis=1,inplace=True)\n",
    "# original_data['user_id'] = original_data.user_id.astype(int)\n",
    "\n",
    "'''这一块代码是数据处理'''\n",
    "retail_data = pd.read_csv('/home/wyf/Desktop/tmall/train.csv')\n",
    "# retail_data = pd.read_csv('train.csv')\n",
    "retail_data.drop(retail_data.columns[0],axis=1,inplace=True)\n",
    "\n",
    "retail_data['user_id'] = retail_data.user_id.astype(int)\n",
    "data = retail_data[['user_id', 'item_id', 'Occurrence']] # Get rid of unnecessary info\n",
    "\n",
    "item_lookup = retail_data[['item_id', 'cat_id']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['item_id'] = retail_data.item_id.astype(int) # Encode as strings for future lookup ease\n",
    "\n",
    "grouped_cleaned = data.groupby(['user_id', 'item_id']).sum().reset_index() # Group together\n",
    "grouped_cleaned.Occurrence.loc[grouped_cleaned.Occurrence == 0] = 1\n",
    "grouped_purchased = grouped_cleaned.query('Occurrence > 0')\n",
    "\n",
    "customers = list(np.sort(grouped_purchased.user_id.unique())) # Get our unique customers\n",
    "products = list(grouped_purchased.item_id.unique()) # Get our unique products that were purchased\n",
    "quantity = list(grouped_purchased.Occurrence)\n",
    "\n",
    "rows = grouped_purchased.user_id.astype('category', categories = customers).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = grouped_purchased.item_id.astype('category', categories = products).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))\n",
    "\n",
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity  # sparsity is 99.92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这里用不到user_info'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''这里用不到user_info'''\n",
    "# temp = retail_data[retail_data['user_id'].isin(customers)]\n",
    "# user_info1 = temp[['user_id','age_range','gender']]\n",
    "# user_info = user_info1.drop_duplicates(subset=['user_id'])\n",
    "# # print(user_info)\n",
    "# new_user_info = pd.get_dummies(user_info, columns=['gender'])\n",
    "# user_info = pd.get_dummies(new_user_info, columns=['age_range'])\n",
    "# user_info.rename(columns={'user_id':'UserId'},inplace = True)\n",
    "# user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     2,      5,     14, ..., 424153, 424157, 424167])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_arr = np.array(customers) # Array of customer IDs from the ratings matrix\n",
    "products_arr = np.array(products) # Array of product IDs from the ratings matrix\n",
    "customers_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(customers_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14783, 796443),\n",
       " (368853, 210741),\n",
       " (146302, 288118),\n",
       " (135570, 261644),\n",
       " (14094, 417530)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('/home/wyf/Desktop/tmall/test.txt', 'rb') as fp:\n",
    "# with open ('test.txt', 'rb') as fp:\n",
    "    test_set = pickle.load(fp) # 在explicit with cmf的变量名叫做product_users_altered\n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n",
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 40.0/40 [00:14<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "'''这里是矩阵分解'''\n",
    "alpha = 40\n",
    "user_vecs, item_vecs = implicit.alternating_least_squares((purchases_sparse*alpha).astype('double'), \n",
    "                                                          factors=40, \n",
    "                                                          regularization = 0.1, \n",
    "                                                         iterations = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_items(customer_id, mf_train, user_vecs, item_vecs, customer_list, item_list, item_lookup, num_items = 10):\n",
    "    '''\n",
    "    This function will return the top recommended items to our users \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to get recommendations for\n",
    "    \n",
    "    mf_train - The training matrix you used for matrix factorization fitting\n",
    "    \n",
    "    user_vecs - the user vectors from your fitted matrix factorization\n",
    "    \n",
    "    item_vecs - the item vectors from your fitted matrix factorization\n",
    "    \n",
    "    customer_list - an array of the customer's ID numbers that make up the rows of your ratings matrix \n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_list - an array of the products that make up the columns of your ratings matrix\n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    num_items - The number of items you want to recommend in order of best recommendations. Default is 10. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - The top n recommendations chosen based on the user/item vectors for items never interacted with/purchased\n",
    "    '''\n",
    "    \n",
    "    cust_ind = np.where(customer_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    pref_vec = mf_train[cust_ind,:].toarray() # Get the ratings from the training set ratings matrix\n",
    "    pref_vec = pref_vec.reshape(-1) + 1 # Add 1 to everything, so that items not purchased yet become equal to 1\n",
    "    pref_vec[pref_vec > 1] = 0 # Make everything already purchased zero\n",
    "    rec_vector = user_vecs[cust_ind,:].dot(item_vecs.T) # Get dot product of user vector and all item vectors\n",
    "#     print(rec_vector)\n",
    "    # Scale this recommendation vector between 0 and 1\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "#     print(rec_vector_scaled)\n",
    "    recommend_vector = pref_vec*rec_vector_scaled\n",
    "    # Items already purchased have their recommendation multiplied by zero\n",
    "    product_idx = np.argsort(recommend_vector)[::-1][:num_items] # Sort the indices of the items into order \n",
    "    # of best recommendations\n",
    "    rec_list = [] # start empty list to store items\n",
    "    for index in product_idx:\n",
    "        code = item_list[index]\n",
    "#         rec_list.append([code, item_lookup.Description.loc[item_lookup.StockCode == code].iloc[0]]) \n",
    "        rec_list.append([code, item_lookup.cat_id.loc[item_lookup.item_id == code].iloc[0]]) \n",
    "        # Append our descriptions to the list\n",
    "    codes = [item[0] for item in rec_list]\n",
    "    descriptions = [item[1] for item in rec_list]\n",
    "    final_frame = pd.DataFrame({'item_id': codes, 'cat_id': descriptions}) # Create a dataframe \n",
    "    return final_frame[['item_id', 'cat_id']] # Switch order of columns around\n",
    "\n",
    "# total_rec = rec_items(, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,num_items = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(item, _list):\n",
    "    if item in _list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7304347826086957"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc_topN_with_cat(altered_pair, num):\n",
    "    count = 0\n",
    "#     print(len(altered_pair))\n",
    "    for i in range(len(altered_pair)):\n",
    "#         print(altered_pair[i])\n",
    "        total_rec = rec_items(altered_pair[i][0], purchases_sparse, user_vecs, item_vecs, customers_arr, products_arr, item_lookup, num_items = 100)\n",
    "#         print(total_rec)\n",
    "        cat_topN = list(total_rec.groupby('cat_id').head(num).item_id)\n",
    "#         print(cat_topN)\n",
    "#         print(len(cat_topN))\n",
    "        count = count + accuracy(altered_pair[i][1], cat_topN)\n",
    "    return count/len(altered_pair)\n",
    "\n",
    "topN_acc = acc_topN_with_cat(test_set, 5)\n",
    "topN_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
